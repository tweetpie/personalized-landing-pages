{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step5: Topic Modeling and Classification\n",
    "\n",
    "In this notebook, we perform topic modeling and classification on a dataset of tweets. The primary objectives are to identify topics within the tweets and classify each tweet into predefined categories. The workflow involves the following steps:\n",
    "\n",
    "#### Cluster Related Tweets\n",
    "- Load the codebook, clustered tweets with embeddings, and manually labeled cluster samples.\n",
    "- Calculate the percentage of tweets related to the event for each cluster.\n",
    "- Filter tweets based on related clusters.\n",
    "\n",
    "#### Topic Modeling with Guided LDA\n",
    "- Create a dictionary of codebook categories and associated n-grams.\n",
    "- Vectorize the related tweets using CountVectorizer with specified parameters.\n",
    "- Use GuidedLDA for topic modeling, considering seed topics from the codebook.\n",
    "- Evaluate the model on a test set for different window sizes.\n",
    "**Note**: You can check the [GuidedLDA Installation Workaround](https://github.com/dex314/GuidedLDA_WorkAround) for installation instructions. \n",
    "\n",
    "#### Topic Modeling with BERTopic\n",
    "- Utilize the SentenceTransformer model for embedding tweets.\n",
    "- Apply BERTopic for topic modeling, considering seed topics from the codebook.\n",
    "- Evaluate the model on a test set for different window sizes.\n",
    "\n",
    "#### Topic Modeling with BERT and RoBERTa\n",
    "- Use pre-trained BERT and RoBERTa models for tweet embeddings.\n",
    "- Apply embeddings to seed topics and tweets for classification.\n",
    "- Evaluate both models on a test set for different window sizes.\n",
    "\n",
    "#### Topic Modeling with GloVe Embeddings\n",
    "- Load GloVe embeddings and create embeddings for seed topics.\n",
    "- Apply GloVe embeddings to tweets for classification.\n",
    "- Evaluate the model on a test set for different window sizes.\n",
    "\n",
    "**Note**: The final evaluation scores for each method and model are printed for different window sizes.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ad1a4fb2ea5bd52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "from lda import guidedlda\n",
    "from transformers import BertModel, BertTokenizer, RobertaModel, RobertaTokenizer\n",
    "\n",
    "from utils import enhanced_stop_words, preprocess_tweet, calculate_topic_modeling_score\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "codebook = pd.read_csv('../data/intermediate/input/step_5_codebook_manually_labeled.csv')\n",
    "tweets_df = pickle.load(open('../data/intermediate/input/step_4_clustered_tweets_with_embeddings.pkl', 'rb'))\n",
    "labeled_clusters_df = pd.read_csv('../data/intermediate/input/step_4_cluster_samples_manually_labeled.csv')\n",
    "# for each cluster sum is_related column and divide by the number of tweets in the cluster\n",
    "# to get the percentage of tweets that are related to the event\n",
    "cluster_relatedness_df = labeled_clusters_df.groupby('cluster').agg({'is_related': 'sum', 'id': 'count'}).reset_index()\n",
    "cluster_relatedness_df['relatedness'] = cluster_relatedness_df['is_related'] / cluster_relatedness_df['id']\n",
    "cluster_relatedness_df['is_related'] = cluster_relatedness_df['relatedness'] > 0.5\n",
    "cluster_relatedness_df = cluster_relatedness_df[['cluster', 'is_related']]\n",
    "related_tweets_df = tweets_df[tweets_df['cluster'].isin(cluster_relatedness_df[cluster_relatedness_df['is_related']]['cluster'].tolist())]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d50e79ce0eeb8a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dictionary of codebook as key is the category and value is the list of n_grams\n",
    "codebook_dict = {x: codebook.loc[codebook['category'] == x, 'n_gram'].tolist() for x in codebook['category'].unique()}\n",
    "category_ids = {x: i for i, x in enumerate(codebook['category'].unique())}\n",
    "category_ids_inv = {i: x for i, x in enumerate(codebook['category'].unique())}\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), min_df=0.001, max_df=0.85, stop_words=enhanced_stop_words)\n",
    "v_fit = vectorizer.fit_transform(related_tweets_df['processed_text'].tolist())\n",
    "word2id = dict((v, idx) for idx, v in enumerate(vectorizer.get_feature_names_out()))\n",
    "\n",
    "seed_topics = {}\n",
    "for cagegory, seed_words in codebook_dict.items():\n",
    "    for word in seed_words:\n",
    "        if word not in word2id:\n",
    "            continue\n",
    "        seed_topics[word2id[word]] = category_ids[cagegory]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e326de18b12a68b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TOPIC_NUMBER = 10\n",
    "NITER = 25\n",
    "ALPHA = .3 #\n",
    "ETA = .05\n",
    "CONF = 1\n",
    "IN_OR_OUT = 1\n",
    "TOP_N_WORDS = 20\n",
    "window_sizes = [0, 1, 2, 5]\n",
    "\n",
    "model = guidedlda.GuidedLDA(\n",
    "        n_topics=TOPIC_NUMBER,\n",
    "        n_iter=NITER,\n",
    "        random_state=0,\n",
    "        alpha=ALPHA,\n",
    "        eta=ETA\n",
    "    )\n",
    "model.fit(v_fit, seed_topics=seed_topics, seed_confidence=CONF)\n",
    "test_set_df = pd.read_csv('../data/test_set_for_topic_modeling.csv')\n",
    "test_set_df['processed_text'] = test_set_df['text'].apply(preprocess_tweet)\n",
    "test_set_df['vectorized_text'] = test_set_df['processed_text'].apply(lambda x: vectorizer.transform([x]))\n",
    "# get top5 topics for each tweet as cat1_pred, cat2_pred, cat3_pred, cat4_pred, cat5_pred\n",
    "test_set_df['topic_predictions'] = test_set_df['vectorized_text'].apply(lambda x: model.transform(x)[0])\n",
    "for i in range(1,6):\n",
    "    test_set_df[f'cat{i}_pred'] = test_set_df['topic_predictions'].apply(lambda x: category_ids_inv.get(np.argsort(x)[-i]))\n",
    "    \n",
    "for window_size in window_sizes:\n",
    "    accuracy = calculate_topic_modeling_score(test_set_df, window_size)\n",
    "    print(f'Score for window size {window_size}: {accuracy:.2f}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a39fdd68008c04c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
    "bertopic_model = BERTopic(seed_topic_list=list(codebook_dict.values()), n_gram_range=(1, 3), embedding_model=sentence_model,\n",
    "                        min_topic_size=10, calculate_probabilities=True, verbose=True, nr_topics=TOPIC_NUMBER, top_n_words=TOP_N_WORDS)\n",
    "tweets = tweets_df[\"processed_text\"].tolist()\n",
    "bertopic_model.fit(tweets)\n",
    "test_set_df = pd.read_csv('../data/test_set_for_topic_modeling.csv')\n",
    "test_set_df['processed_text'] = test_set_df['text'].apply(preprocess_tweet)\n",
    "test_set_df['topic_predictions'] = test_set_df['processed_text'].apply(lambda x: bertopic_model.transform([x])[0])\n",
    "for i in range(1,6):\n",
    "    test_set_df[f'cat{i}_pred'] = test_set_df['topic_predictions'].apply(lambda x: category_ids_inv.get(np.argsort(x)[-i]))\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    accuracy = calculate_topic_modeling_score(test_set_df, window_size)\n",
    "    print(f'Score for window size {window_size}: {accuracy:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "500f108c93a3233a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from source.utils import get_pretrained_model_and_tokenizer\n",
    "\n",
    "model_name = 'bert' # options are bert, roberta, sbert, sroberta\n",
    "model, tokenizer = get_pretrained_model_and_tokenizer(model_name)\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "test_set_df = pd.read_csv('../data/test_set_for_topic_modeling.csv')\n",
    "test_set_df['processed_text'] = test_set_df['text'].apply(preprocess_tweet)\n",
    "\n",
    "seed_topics_embeddings = []\n",
    "for seed_words in codebook_dict.values():\n",
    "    seed_topics_embeddings.append(model(**tokenizer(seed_words, return_tensors=\"pt\", padding=True, truncation=True).to(device))['last_hidden_state'].mean(dim=0).detach().cpu().numpy())\n",
    "test_set_df['embedding'] = test_set_df['processed_text'].apply(lambda x: model(**tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True).to(device))['last_hidden_state'].mean(dim=0).detach().cpu().numpy())\n",
    "test_set_df['topic_predictions'] = test_set_df['embedding'].apply(lambda x: np.argsort([np.dot(x, y) for y in seed_topics_embeddings]))\n",
    "for i in range(1,6):\n",
    "    test_set_df[f'cat{i}_pred'] = test_set_df['topic_predictions'].apply(lambda x: category_ids_inv.get(x[-i]))\n",
    "    \n",
    "\n",
    "for window_size in window_sizes:\n",
    "    accuracy = calculate_topic_modeling_score(test_set_df, window_size)\n",
    "    print(f'Score for window size {window_size}: {accuracy:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ed3e463794f2cb7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = 'roberta' # options are bert, roberta, sbert, sroberta\n",
    "model, tokenizer = get_pretrained_model_and_tokenizer(model_name)\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "test_set_df = pd.read_csv('../data/test_set_for_topic_modeling.csv')\n",
    "test_set_df['processed_text'] = test_set_df['text'].apply(preprocess_tweet)\n",
    "\n",
    "seed_topics_embeddings = []\n",
    "for seed_words in codebook_dict.values():\n",
    "    seed_topics_embeddings.append(model(**tokenizer(seed_words, return_tensors=\"pt\", padding=True, truncation=True).to(device))['last_hidden_state'].mean(dim=0).detach().cpu().numpy())\n",
    "test_set_df['embedding'] = test_set_df['processed_text'].apply(lambda x: model(**tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True).to(device))['last_hidden_state'].mean(dim=0).detach().cpu().numpy())\n",
    "test_set_df['topic_predictions'] = test_set_df['embedding'].apply(lambda x: np.argsort([np.dot(x, y) for y in seed_topics_embeddings]))\n",
    "for i in range(1,6):\n",
    "    test_set_df[f'cat{i}_pred'] = test_set_df['topic_predictions'].apply(lambda x: category_ids_inv.get(x[-i]))\n",
    "    \n",
    "\n",
    "for window_size in window_sizes:\n",
    "    accuracy = calculate_topic_modeling_score(test_set_df, window_size)\n",
    "    print(f'Score for window size {window_size}: {accuracy:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e13a2b2c0e0ab367"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "glove_embeddings_dict = {}\n",
    "with open(\"../data/glove/glove.twitter.27B.200d.txt\", 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        glove_embeddings_dict[word] = vector\n",
    "\n",
    "seed_topics_embeddings = []\n",
    "ngrams = list(codebook_dict.values())\n",
    "# split ngrams into words per category\n",
    "ngrams = [[x.split() for x in y] for y in ngrams]\n",
    "words = []\n",
    "for x in ngrams:\n",
    "    flatten_list = [item for sublist in x for item in sublist]\n",
    "    words.append(flatten_list)\n",
    "for seed_words in words:\n",
    "    seed_topics_embeddings.append(np.mean([glove_embeddings_dict.get(x) for x in seed_words if x in glove_embeddings_dict], axis=0))\n",
    "    \n",
    "test_set_df = pd.read_csv('../data/test_set_for_topic_modeling.csv')\n",
    "test_set_df['processed_text'] = test_set_df['text'].apply(preprocess_tweet)\n",
    "test_set_df['embedding'] = test_set_df['processed_text'].apply(lambda x: np.mean([glove_embeddings_dict.get(y) for y in x.split() if y in glove_embeddings_dict], axis=0))\n",
    "test_set_df['topic_predictions'] = test_set_df['embedding'].apply(lambda x: np.argsort([np.dot(x, y) for y in seed_topics_embeddings]))\n",
    "\n",
    "for i in range(1,6):\n",
    "    test_set_df[f'cat{i}_pred'] = test_set_df['topic_predictions'].apply(lambda x: category_ids_inv.get(x[-i]))\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    accuracy = calculate_topic_modeling_score(test_set_df, window_size)\n",
    "    print(f'Score for window size {window_size}: {accuracy:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9db614c6d6b30fd4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
